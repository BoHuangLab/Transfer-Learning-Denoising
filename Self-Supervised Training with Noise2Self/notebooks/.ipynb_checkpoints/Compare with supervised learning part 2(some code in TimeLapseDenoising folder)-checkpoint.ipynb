{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yina/DeepDenoising/noise2self\n",
      "GPU device 0 has 7343 MiB left.\n",
      "--> GPU device 0 was chosen\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "import torch\n",
    "from util import getbestgpu\n",
    "device = getbestgpu(1)\n",
    "from torch.nn import MSELoss\n",
    "from torch.optim import Adam\n",
    "from models.unet import Unet\n",
    "\n",
    "model = Unet()\n",
    "\n",
    "loss_function = MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "from mask import Masker\n",
    "masker = Masker(width = 4, mode='interpolate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mdata\u001b[0m/               environment.yml   mask.py                    \u001b[01;34m__pycache__\u001b[0m/\r\n",
      "data_loader_FMD.py  \u001b[01;34mfigs\u001b[0m/             metric.py                  README.md\r\n",
      "data_loader.py      \u001b[01;34mgaussianprocess\u001b[0m/  microtubule_simulation.py  structures.py\r\n",
      "data_loader_Sim.py  index.html        \u001b[01;34mmodels\u001b[0m/                    train.py\r\n",
      "\u001b[01;35mdenoised_self.tiff\u001b[0m  LICENSE           \u001b[01;34mnotebooks\u001b[0m/                 util.py\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yina/DeepDenoising/TimelapseDenoise\n",
      "(50, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "%cd /home/yina/DeepDenoising/TimelapseDenoise\n",
    "import tifffile as tiff\n",
    "noisy = tiff.imread('noisy.tiff')\n",
    "movie = tiff.imread('clean.tiff')\n",
    "print(noisy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yina/DeepDenoising/noise2self\n"
     ]
    }
   ],
   "source": [
    "%cd /home/yina/DeepDenoising/noise2self\n",
    "from data_loader import ConfocalDataset\n",
    "import numpy as np\n",
    "\n",
    "dataset = ConfocalDataset([np.expand_dims(noisy[0:20,:],1), np.expand_dims(movie[0:20,:],1)])\n",
    "kwargs = {'num_workers': 4, 'pin_memory': True} \\\n",
    "              if torch.cuda.is_available() else {}\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=50, \n",
    "                  shuffle=True, drop_last=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9] loss: 0.03014 val_loss: 0.03280\n",
      "[19] loss: 0.01550 val_loss: 0.01312\n",
      "[29] loss: 0.00731 val_loss: 0.00709\n",
      "[39] loss: 0.00548 val_loss: 0.00557\n",
      "[49] loss: 0.00538 val_loss: 0.00514\n",
      "[59] loss: 0.00469 val_loss: 0.00478\n",
      "[69] loss: 0.00441 val_loss: 0.00463\n",
      "[79] loss: 0.00458 val_loss: 0.00454\n",
      "[89] loss: 0.00429 val_loss: 0.00444\n",
      "[99] loss: 0.00420 val_loss: 0.00438\n",
      "[109] loss: 0.00429 val_loss: 0.00434\n",
      "[119] loss: 0.00417 val_loss: 0.00431\n",
      "[129] loss: 0.00413 val_loss: 0.00429\n",
      "[139] loss: 0.00415 val_loss: 0.00431\n",
      "[149] loss: 0.00415 val_loss: 0.00428\n",
      "[159] loss: 0.00416 val_loss: 0.00424\n",
      "[169] loss: 0.00411 val_loss: 0.00426\n",
      "[179] loss: 0.00410 val_loss: 0.00422\n",
      "[189] loss: 0.00408 val_loss: 0.00422\n",
      "[199] loss: 0.00412 val_loss: 0.00424\n",
      "[209] loss: 0.00411 val_loss: 0.00419\n",
      "[219] loss: 0.00405 val_loss: 0.00417\n",
      "[229] loss: 0.00411 val_loss: 0.00420\n",
      "[239] loss: 0.00411 val_loss: 0.00425\n",
      "[249] loss: 0.00420 val_loss: 0.00416\n",
      "[259] loss: 0.00407 val_loss: 0.00422\n",
      "[269] loss: 0.00408 val_loss: 0.00417\n",
      "[279] loss: 0.00402 val_loss: 0.00416\n",
      "[289] loss: 0.00408 val_loss: 0.00415\n"
     ]
    }
   ],
   "source": [
    "from train import train\n",
    "model = model.to(device)\n",
    "model = train(model, data_loader, 'mse', optimizer,300, \\\n",
    "                  masker, earlystop=True, patience=3, device=device, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.from_numpy(np.expand_dims(noisy[0:20,:],1)).to(device)\n",
    "denoised_self = model(input)\n",
    "\n",
    "tiff.imwrite('denoised_self.tiff', np.squeeze(denoised_self.cpu().detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yina/DeepDenoising/noise2self\n",
      "(20, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "# calculate MAE and SSMI\n",
    "%cd /home/yina/DeepDenoising/noise2self\n",
    "import tifffile as tiff\n",
    "noisy = tiff.imread('denoised_self_peak50_gauss10_samewithtraining.tiff')\n",
    "movie = tiff.imread('clean.tiff')\n",
    "print(noisy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "n2s",
   "language": "python",
   "name": "n2s"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
